{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Flatten, Dense, ReLU, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load('dados.npz')\n",
    "\n",
    "# Training set\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "\n",
    "# Test set\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data summary\n",
    "print(f'X_train = {X_train.shape}')\n",
    "print(f'y_train = {y_train.shape}')\n",
    "print(f'X_test = {X_test.shape}')\n",
    "print(f'y_test = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network implementation\n",
    "rate_drop = 0.5\n",
    "initializer='he_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = Input(shape=X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "conv_1 = Conv1D(kernel_size=16, filters=64, strides=1, padding=\"same\", kernel_initializer=initializer)(input_layer)\n",
    "bn_1 = BatchNormalization()(conv_1)\n",
    "relu_1 = ReLU()(bn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second layer\n",
    "conv_2 = Conv1D(kernel_size=16, filters=64, strides=1, padding=\"same\", kernel_initializer=initializer)(relu_1)\n",
    "bn_2 = BatchNormalization()(conv_2)\n",
    "relu_2 = ReLU()(bn_2)\n",
    "drop_1 = Dropout(rate_drop)(relu_2)\n",
    "conv_3 = Conv1D(kernel_size = 16, filters=64, strides=2, padding=\"same\", kernel_initializer=initializer)(drop_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short connection\n",
    "short_1 = MaxPooling1D(pool_size=1, strides=2)(relu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding layers\n",
    "layers = Add()([conv_3, short_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_blocks(x, stride=1, num_filter = 64):\n",
    "    bn_1 = BatchNormalization()(x)\n",
    "    relu_1 = ReLU()(bn_1)\n",
    "    drop_1 = Dropout(rate_drop)(relu_1)\n",
    "    conv_1 = Conv1D(kernel_size=16, filters=num_filter, strides=1, padding=\"same\", kernel_initializer=initializer)(drop_1)\n",
    "    bn_2 = BatchNormalization()(conv_1)\n",
    "    relu_2 = ReLU()(bn_2)\n",
    "    drop_2 = Dropout(rate_drop)(relu_2)\n",
    "    conv_2 = Conv1D(kernel_size=16, filters=num_filter, strides=stride, padding=\"same\", kernel_initializer=initializer)(drop_2)\n",
    "\n",
    "    if i == 3 or i == 7 or i == 11:  #Verifica se houve mudança na quantidade de número de filtros\n",
    "        #Short connection\n",
    "        conv_aj = Conv1D(kernel_size=16, filters=num_filter, strides=1, padding=\"same\")(x) #Ajustar o número de filtros\n",
    "        short = MaxPooling1D(pool_size = 1, strides=2)(conv_aj)\n",
    "    else:\n",
    "        #Short connection\n",
    "        short = MaxPooling1D(pool_size = 1, strides=stride)(x)\n",
    "\n",
    "    # Adding layers\n",
    "    return Add()([conv_2, short])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = np.array([64, 64, 64, 128, 128, 128, 128, 192, 192, 192, 192, 256, 256, 256, 256])\n",
    "for i in range(15):\n",
    "    #print(f\"i = {i} STRIDE = {(i % 2)+1}, FILTER LENGHT = {num_filter[i]}\")\n",
    "    layers = residual_blocks(layers, stride=(i % 2)+1, num_filter = num_filter[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last layers\n",
    "# The ﬁnal fully connected layer and sigmoid activation produce a distribution \n",
    "# over the 5 output superclasses for each time-step.\n",
    "bn_x = BatchNormalization()(layers)\n",
    "relu_x = ReLU()(bn_x)\n",
    "flat_x = Flatten()(relu_x)\n",
    "dense_x = Dense(32)(flat_x)\n",
    "classification = Dense(5, activation='sigmoid')(dense_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the model\n",
    "model = Model(inputs=input_layer, outputs=classification)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros de otimização\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otimizador Adam\n",
    "opt = Adam(lr, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "# filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "\n",
    "#Reduz a taxa de aprendizagem quando o erro de validação para de melhorar\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=lr/10000))\n",
    "# callbacks.append(EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10))\n",
    "# callbacks.append(ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino do modelo\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test: open the hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/sarah/TCC/5-Arquiteturas/Weights improvement/weights-improvement-08-0.89.hdf5','r')\n",
    "# ls = list(hf.keys())\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(hf.keys())\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = hf.get(ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_weights = hf.get(ls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight = np.array(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_weight = np.array(optimizer_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.plot(history.epoch, history.history['loss'], '-o')\n",
    "plt.plot(history.epoch, history.history['val_loss'], '-*')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend(['Training set', 'Validation set'])\n",
    "local = 'E:/Usuários/Sarah/Documentos/UTFPR/TCC/Resultados/Gráficos/Custo_atual_callbacks'\n",
    "plt.savefig(local)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'], '-o')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'], '-*')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training set', 'Validation set'])\n",
    "local = 'E:/Usuários/Sarah/Documentos/UTFPR/TCC/Resultados/Gráficos/Acuracia_atual_callbacks'\n",
    "plt.savefig(local)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(f\"Custo de teste = {score[0]:.4f}\")\n",
    "print(f\"Acurácia de teste = {100*score[1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of the model\n",
    "prediction = model.predict(X_test) #Realiza a predição das probabilidades de cada label\n",
    "prediction_bin = np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the probabilities of each label, if it is higher or equal to 0.5, that is the class of the diagnostic\n",
    "for indice in range(prediction_bin.shape[0]):\n",
    "    for i in range(prediction_bin.shape[1]):\n",
    "        if prediction_bin[indice][i] >= 0.5:\n",
    "            prediction_bin[indice][i] = 1\n",
    "        else:\n",
    "            prediction_bin[indice][i] = 0\n",
    "prediction_bin = np.array(prediction_bin,dtype='int')\n",
    "#Example of index 67\n",
    "print(f'Prediction: {prediction_bin[67]} \\t\\tReal Label: {y_test[67]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List with the labels strings\n",
    "label_string = ['NORM','MI','CD','STTC','HYP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the binary vector in a list with strings (could be y_test or the predictions)\n",
    "def get_strings(label_string,label_bin):\n",
    "    label_bin_string = []\n",
    "    for x in range(len(label_bin)):\n",
    "        lst = []\n",
    "        for y in range(len(label_string)):\n",
    "            value = label_bin[x][y]\n",
    "            if value == 1:\n",
    "                lst.append(label_string[y])\n",
    "        label_bin_string.append(lst)\n",
    "    \n",
    "    return label_bin_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_test string labels\n",
    "y_test_string = get_strings(label_string, y_test)\n",
    "\n",
    "#Predictions strings labels\n",
    "prediction_string = get_strings(label_string, prediction_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing an example\n",
    "index = 67\n",
    "print(f'Index: {index}\\n')\n",
    "\n",
    "print(f'Diagnostic = {y_test[index]}')\n",
    "print(f'Prediction = {prediction_bin[index]}\\n')\n",
    "\n",
    "print(f'Diagnostic = {y_test_string[index]}')\n",
    "print(f'Prediction = {prediction_string[index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy from the example below\n",
    "acc_index = accuracy_score(y_test[index],prediction_bin[index])\n",
    "print(f'Example accuracy = {100 * acc_index:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the example with the diagnostic and prediction\n",
    "valor_med = X_test[index, ].mean(axis=-1)\n",
    "fig_s, ax_s = plt.subplots(figsize=(10,7))\n",
    "ax_s.set_title(f'Diagnostic: {y_test_string[index]}       Prediction:{prediction_string[index]}')\n",
    "ax_s.plot(valor_med)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another metrics\n",
    "report = classification_report(y_test,prediction_bin,output_dict=True,target_names=['NORM', 'MI', 'CD', 'STTC', 'HYP'])\n",
    "report_df = pd.DataFrame.from_dict(report, orient='index')\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion marix\n",
    "cm = multilabel_confusion_matrix(y_test, prediction_bin)\n",
    "\n",
    "# https://www.kaggle.com/code/trolukovich/multi-label-classification-keras/notebook\n",
    "# Plot confusion matrix \n",
    "fig = plt.figure(figsize = (14, 8))\n",
    "for i, (label, matrix) in enumerate(zip(label_string, cm)):\n",
    "    plt.subplot(f'23{i+1}')\n",
    "    labels = [f'Not {label}', label]\n",
    "    sns.heatmap(matrix, annot = True, square = True, fmt = 'd', cbar = False, cmap = 'Blues', \n",
    "                xticklabels = labels, yticklabels = labels, linecolor = 'black', linewidth = 1)\n",
    "    plt.title(label)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
